\chapter{Robert - \emph{Spell checking}}

Robert est un module capable de détecter le langage utilisé dans un texte donné, et éventuellement
 indiquer à l'utilisateur les différentes fautes que peut contenir ledit document en lui donnant une
sélection de mots considérés comme étant probables.  

\section{Generation of Dictionnaries}
Un dictionnaire est un fichier contenant un ensemble de mots, appartenant à une langue spécifique,
que l'on peut retrouver dans un texte.\\
Nous ne les avons pas généré, c'est un travail bien trop fastidieux, d'autant plus qu'il est aisé d'en
trouver sur Internet, sous la forme de fichier texte doté d'un mot par ligne ; Par exemple, un dictionnaire
anglais ne contient pas moins de 150 000 mots, et le dictionnaire français passe la barre des 700 000.
Seulement, si à chaque fois que l'on souhaitait vérifier l'existence d'un mot dans une langue donnée, il
faille parcourir les 700 000 lignes du fichier de manière séquentielle, le temps pris risque d'être énorme,
d'autant plus qu'un texte n'est généralement pas composé d'un seul mot, mais de plusieurs centaines, voir des
milliers. C'est pourquoi nous effectuons un prétraitement lors de l'ajout d'une langue à Robert : il s'agit
de la génération d'une structure de données au temps de recherche constant contenant l'ensemble des mots
appartenant à la langue donnée : La table de hashage, ou hashtable s'est donc imposée par défaut, grâce à
son temps de recherche constant, quelque soit la taille de l'ensemble qu'elle contient. \\
Ainsi, lors du chargement de Robert, OCaml va générer à partir des fichiers dictionnaires de chaque langue
reconnue des nouveaux dictionnaires (qui sont des hashtable)  reconnaissant la langue en RAM. \\
Un dernier soucis reste que la génération de ces dictionnaires nécéssitent obligatoirement une lecture
séquentielle de la hashtable, ainsi qu'un certain nombre de calculs quant à leur générations. \\Au final,
le chargement entier de la table de hash à partir du fichier texte ne prend pas moins de 1 seconde par langage.
Dans le doute, si jamais Robert devait être capable de gérer plusieurs dizaines de langages, le programme prendrait
pas moins de plusieurs dizains de secondes, rien qu'au chargement du module.

La solution a été trouvée grâce au module Marshall D'OCaml, qui permet de sérialiser un object en un tableau de bytes,
c'est à dire de copier sa représentation RAM dans un tableau de byte, et inversement. L'intérêt majeur est qu'il s'agit
d'une opération peu chère, qui permet de sauvegarder alors ce tableau dans un fichier binaire, pour le recharger
éventuellement plus tard. La génération du dictionnaire à partir du fichier source n'a alors à être réalisée qu'une
seule et unique fois par les développeurs, et Robert chargera et désérializera alors les dictionnaires à chaque fois
où KibiOCR sera appelé. Le gain apporté est assez conséquent, étant donné que l'on peut constater d'une ammélioration
de vitesse approchant les 1 000\%

\section{Detecting language in a given Text}
L'algorithme de détection de langage actuellement utilisé est assez simple et redoutable d'efficacité :\\
Il analyse les X premiers mots (ou moins si le texte en fait moins) du texte qu'on lui donnera ; pour chaque langage, il contera alors le nombre de mots
reconnus. Une fois au les X mots traités, le langage retenu par la détection sera alors celui ayant le plus de termes reconnus.\\
\\
La constante X a été définie à 200, ce qui reste un nombre raisonnable du point de vue temps pris, tout en permettant de passer outre les
éventuelles erreurs que le texte peut comporter.\\
\section{Detection of wrong words}
It's quite the same thing. The algorithm make a list, and starts to read the whole text. Each time a word is wrong, it is added to the list.
\section{Selection of possible corrections for a wrong word}
Generally, when a word is wrong, it's because the user writted it thinking about a right word, with the same pronunciation.\\
That's why the Soundex algorithm has been used in our project. It transforms a given string into its phonetic equivalent.
So, we created a new type of dictionnary : a "phonetic hashtable" : we can find the word by searching the phonetic string.
So, if we're searching a phonetic string we can find the whole words which have the same phonetic string.
We have a first list with a lot of possible corrections.\\
But we won't give for examples 42 possibilies of correction to a wrong word: the user would be lost ; that's why we'll give
to the user only 5 possibilities.\\
The possibilities will be sorted using another algorithm, called Levenshtein.
Levenshtein calculates the number of modifications we have to make in order to change a word A into a word B.
So, we'll only have the 5 words which are the closest to the wrong word. 
