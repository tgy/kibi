\chapter{Lenna -- \emph{Preprocessing}}
Avant d'essayer de détecter les paragraphes, les lignes ainsi que les caractères dans l'image, et de reconnaître les caractères, il faut "nettoyer" l'image. Dans ce chapitre nous allons décrire différents algorithmes que nous avons implémentés dans ce but.\\

\section{Binarisation}
C'est le premier algorithme que nous avons écrit parce qu'il est simple, essentiel et c'est un bon point de départ pour se familiariser avec la bibliothèque et ses fonctions de base. Nous avons d'abord implémenté la méthode la plus naïve : calculer la moyenne des composantes RGB de chaque pixel pour avoir sa luminosité, et appliquer un seuil. Tout pixel dont la luminosité est en dessous de 127 est considéré comme blanc et les autres comme noir. Evidemment, ce ne fut pas notre algorithme définitif.\\

Nous aurions pu l'améliorer en prenant comme seuil la luminosité moyenne des pixels, cependant cela n'aurais pas été beaucoup mieux. Nous avons plutot décidé de rechercher un meilleur algorithme, et avons décidé que la méthode d'Otsu était la plus adaptée à notre cas. De plus cet algorithme est relativement simple à impémenter. La principe de la méthode d'Otsu est de trouver le seuil idéal pour l'algorithme décrit précedemment. Le seui idéal est défini comme étant celui qui minimise la variance entre les deux classes formées par ce seuil. Il faut donc essayer chaque seuil possible et calculer à chaque fois la variance de chaque classe. Heureusement une petite astuce mathématique nous permet de réduire de façon significative la complexité de cet algorithme en maximisant la variance inter-classe au lieu de minimiser la variance intra-classe.\\

\section{Réduction du bruit}

Nous avons éssayé deux méthodes pour réduire le bruit dans l'image : le flou gaussien et le filtre médian. Nous avons été insatisfait des deux car les lettres étaient moins lisible après le filtre. Pour corriger ça, nous avons réduit le nombre de pixel voisins pris en compte dans le filtre median : pour chaque pixel, nous prenons le pixel median parmi le pixel lui même et ses quatre voisins immédiats.\\

\section{Rotation}
\section{Algorithme de base}

Il est très difficile de détecter les zones de texte dans l'image si elle n'est pas droite. Nous avons donc des algorithme pour détecter l'angle du texte dans l'image, puis pour tourner l'image selon cet angle.\\

Une implémentation naïve commencerait par parcourir l'image d'origine et de transposer chaque pixel dans la nouvelle image grâce à une matrice de rotation. Cependant, cet algorithme donnera de très mauvais résultats puisque tous les pixels dans l'image crée n'aurons pas d'antécédants dans l'image d'origine, créant ainsi un effet d'aliasing.

A la place, nous effectuons l'opération inverse : pour chaque pixel de la nouvelle image (encore vide), il faut trouver le pixel correspondant dans l'image d'origine. Il suffit pour cela d'appliquer la matrice de rotation d'angle opposé.

A cause de l'imprecision des coordonnées entières, l'image de sortie n'est pas parfaite. C'est pourquoi nous avons utilisé un algorithme d'interpolation bilinéaire pour conserver la forme des caractères dans l'image avant de commencer la segmentation et l'identification des caractères.

\subsection{Interpolation Bilinéaire}
\subsection{Detection de l'angle}
\subsubsection{Transformée de Hough}

La transformée de Hough est une méthode générale pour trouver des lignes et des ellipses dans une image. Elle est souvent utilisée car une fois le principe mathématique compris, elle est simple à implémenter, donne de bons résultats et à une complexité assez faible par rapport, par exemple, à la transformée de Fourier. Nous n'avons besoin que du cas le plus simple de l'algorithme qui consiste à trouver les lignes dans une image binarisée.

La transformée de Hough se base sur une représentation très particulière des droites du plan : plutot que deux les représenter avec les deux paramètres usuels $a$ et $b$ dans l'équation $y = ax + b$, une droite est décrite comme un couple $(r, \theta)$ où $r$ est la distance de la ligne à l'origine et $\theta$ est l'angle de cette distance par rapport à l'abscisse.

En quoi cette représentation est-elle utile? Cela vient du fait que, étant donné un point de coordonnées $(x, y)$ et l'angle $\theta$ de la droite passant par ce point, il est facile d'exprimer la distance $r$ entre la ligne et l'origine. L'équation est la suivante :\\
$r = x\cos\theta + y\sin\theta$\\
Donc pour un point de coordonnées $(x, y)$ on peut tracer le graphe de $r$ en fonction de $\theta$. Il est facile de deviner d'après l'équation que ce graphe sera une sinusoïde. Cette sinusoïde représente l'ensemble des droites passant par ce point. Si nous stockons ce graphe dans un accumulateur, et ajoutons dans cet accumulateur la sinusoïde correspondant à tous les autres points, on obtient un graphe tableau dans lequel la valeur la plus grande représentera les coordonnées de la droite (dans l'espace de Hough) passant par le plus de points possible.

\subsubsection{More preprocessing}

Il y'a encore un problème à régler avant de pouvoir appliquer la transformée de Hough à notre image scannée : Une ligne de texte n'apparait pas comme une ligne droite. Nous avons essayé d'appliquer directement à une image binarisée, mais la plupart du temps il trouvait ou bien la diagonale de l'image, ou bien une reliure particulièrement visible. Après quelques recherches, nous avons trouvé une solution : on détecte tout d'abord les blocs de pixels noirs connexes, qui ne sont pas toujours mais très souvent des caractères, et on les remplaces par leur point centrale. L'utilité est triple : rendre plus apparentes (du point de vue de la transformée de Hough) les lignes de texte, réduire considérablement la complexité de l'algorithme et reduire l'importance des gros blocs de pixels comme les tâches ou les reliures.

This method has a major flaw that we wish to correct before the end of the
project: when the noise isn't reduced enough, every separate pixel in the
"noisy zone" is considered a block and gets a huge role in the Hough transform,
potentially leading the angle detection to fail completely. Every further step
of the OCR relies on a perfectly straight image, and it is therefore very
important that we correct this. \\
